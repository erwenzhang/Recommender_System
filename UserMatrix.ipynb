{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>978302039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>978302268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1      661       3  978302109\n",
       "1       1      914       3  978301968\n",
       "2       1     3408       4  978300275\n",
       "3       1     1287       5  978302039\n",
       "4       1      594       4  978302268"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide warnings to keep things tidy.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "matplotlib.style.use('ggplot') # make things a bit prettier.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "import math\n",
    "from sklearn import metrics\n",
    "names = ['UserID', 'MovieID', 'Rating', 'Timestamp']\n",
    "df = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/newRatings.csv\", names=names, header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n users: 6040\n",
      "n movies: 1970\n",
      "3951\n"
     ]
    }
   ],
   "source": [
    "n_users = df.UserID.unique().shape[0]\n",
    "print(\"n users: %s\" % n_users)\n",
    "n_movies = df.MovieID.unique().shape[0]\n",
    "print(\"n movies: %s\" % n_movies)\n",
    "max_movies = df.MovieID.unique().max()\n",
    "print max_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.zeros((n_users,max_movies))\n",
    "for row in df.itertuples():\n",
    "    # row[1] will the user_id; row[2] the \n",
    "    # rating (see also my note below).\n",
    "    # the -1 is to move to 0 indexing.\n",
    "    ratings[row[1]-1, row[2]-1] = row[3]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n"
     ]
    }
   ],
   "source": [
    "print ratings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  label\n",
       "0       1      661       3      0\n",
       "1       1      914       3      0\n",
       "2       1      594       4      0\n",
       "3       1      938       4      0\n",
       "4       1     2687       3      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm1 = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/FirstCluster.csv\", header=0)\n",
    "\n",
    "dfm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is used to only select the portion of ratings file that belongs to first cluster. I have already generated the csv and uploaded it to our git. So you need not repeat this step. It is very time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc = pd.read_csv('/Users/sushma/Desktop/DM_Git/Recommender_System/Movies_cluster1.csv', header=0)\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_cluster = []\n",
    "for row in df.itertuples():\n",
    "    for l in dc.itertuples():\n",
    "        if row[2] == l[2]:\n",
    "            first_cluster.append([row[1],row[2],row[3],l[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('/Users/sushma/Desktop/DM_Git/Recommender_System/FirstCluster.csv', 'a') as outcsv:   \n",
    "    writer = csv.writer(outcsv, delimiter=',', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "    writer.writerow(['UserID','MovieID','Rating','label'])\n",
    "    for item in first_cluster:\n",
    "        writer.writerow([item[0], item[1], item[2], item[3]])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the csv file for first cluster, we are going to find all the userID's of first cluster and extract only rows that contain a matching userID from the ratings similarity matrix. Basically, we are first clutering our movies dataset and now creating a similarity matrix for only first cluster so that we can apply knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  label\n",
       "0       1      661       3      0\n",
       "1       1      914       3      0\n",
       "2       1      594       4      0\n",
       "3       1      938       4      0\n",
       "4       1     2687       3      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm1 = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/FirstCluster.csv\", header=0)\n",
    "dfm1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ..., 6038 6039 6040]\n",
      "6037\n"
     ]
    }
   ],
   "source": [
    "unique_userid = dfm1.UserID.unique()\n",
    "unique_userid_length = dfm1.UserID.unique().shape[0]\n",
    "print unique_userid\n",
    "print unique_userid_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix_cluster1 is the similarity matrix extracted from ratings similarity matrix and represents the data that belongs to first cluster only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cluster1 = []\n",
    "for rowid in range(ratings.shape[0]):\n",
    "    if rowid in unique_userid:\n",
    "        list_cluster1.append(ratings[rowid, :])  \n",
    "matrix_cluster1 = np.array(list_cluster1)\n",
    "matrix_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6036, 3951)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_cluster1[5,6]\n",
    "matrix_cluster1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clust1_train, clust1_test = train_test_split(matrix_cluster1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.03800000e+03   1.27000000e+02   7.70000000e+01 ...,   2.00000000e+01\n",
      "    8.50000000e+01   3.71000000e+02]\n",
      " [  1.27000000e+02   3.83000000e+02   3.70000000e+01 ...,   1.00000000e-09\n",
      "    6.60000000e+01   1.81000000e+02]\n",
      " [  7.70000000e+01   3.70000000e+01   1.09000000e+02 ...,   1.00000000e-09\n",
      "    1.50000000e+01   6.10000000e+01]\n",
      " ..., \n",
      " [  2.00000000e+01   1.00000000e-09   1.00000000e-09 ...,   6.60000000e+01\n",
      "    3.70000000e+01   1.90000000e+01]\n",
      " [  8.50000000e+01   6.60000000e+01   1.50000000e+01 ...,   3.70000000e+01\n",
      "    9.92000000e+02   2.69000000e+02]\n",
      " [  3.71000000e+02   1.81000000e+02   6.10000000e+01 ...,   1.90000000e+01\n",
      "    2.69000000e+02   2.58200000e+03]]\n"
     ]
    }
   ],
   "source": [
    "clust1_user_similarity = similarity(clust1_train, kind='user')\n",
    "clust1_item_similarity = similarity(clust1_train, kind='item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared errror for predictions in first cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 9.40684991455\n",
      "Item-based CF MSE: 12.8792060007\n"
     ]
    }
   ],
   "source": [
    "clust1_item_prediction = predict(clust1_train, clust1_item_similarity, kind='item')\n",
    "clust1_user_prediction = predict(clust1_train, clust1_user_similarity, kind='user')\n",
    "\n",
    "print('User-based CF MSE: ' + str(get_mse(clust1_user_prediction, clust1_test)))\n",
    "print('Item-based CF MSE: ' + str(get_mse(clust1_item_prediction, clust1_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The code below is similar to what we learned in class. Creating a similarity matrix for the entire ratings csv (newRatings) and predicting using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 2.43%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(ratings.nonzero()[0]))\n",
    "sparsity /= (ratings.shape[0] * ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        # sample 10 ratings from each user to use\n",
    "        # as 'test' data\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                            size=6, \n",
    "                                            replace=False)\n",
    "        # effectively remove these from the training\n",
    "        # set\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "           \n",
    "    # make sure that test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(ratings, kind='user', epsilon=1e-9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "        print(sim)\n",
    "    elif kind == 'item':\n",
    "        # we need only flip the dimensions around \n",
    "        # to do item based similarity!\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / (norms * norms.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.10000000e+02   4.50000000e+01   3.50000000e+01 ...,   1.00000000e-09\n",
      "    6.80000000e+01   1.44000000e+02]\n",
      " [  4.50000000e+01   1.06800000e+03   1.37000000e+02 ...,   1.50000000e+01\n",
      "    5.60000000e+01   3.58000000e+02]\n",
      " [  3.50000000e+01   1.37000000e+02   3.95000000e+02 ...,   1.00000000e-09\n",
      "    4.00000000e+01   1.35000000e+02]\n",
      " ..., \n",
      " [  1.00000000e-09   1.50000000e+01   1.00000000e-09 ...,   5.90000000e+01\n",
      "    2.50000000e+01   2.50000000e+01]\n",
      " [  6.80000000e+01   5.60000000e+01   4.00000000e+01 ...,   2.50000000e+01\n",
      "    9.76000000e+02   3.03000000e+02]\n",
      " [  1.44000000e+02   3.58000000e+02   1.35000000e+02 ...,   2.50000000e+01\n",
      "    3.03000000e+02   2.59200000e+03]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = similarity(train, kind='user')\n",
    "item_similarity = similarity(train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.10000000e+02,   6.50000000e+01,   3.50000000e+01, ...,\n",
       "          1.00000000e-09,   9.70000000e+01,   1.56000000e+02],\n",
       "       [  6.50000000e+01,   1.06800000e+03,   1.37000000e+02, ...,\n",
       "          1.50000000e+01,   1.01000000e+02,   4.02000000e+02],\n",
       "       [  3.50000000e+01,   1.49000000e+02,   3.95000000e+02, ...,\n",
       "          1.00000000e-09,   4.60000000e+01,   1.69000000e+02],\n",
       "       ..., \n",
       "       [  1.00000000e-09,   5.10000000e+01,   1.60000000e+01, ...,\n",
       "          5.90000000e+01,   3.70000000e+01,   8.00000000e+01],\n",
       "       [  8.00000000e+01,   7.60000000e+01,   6.00000000e+01, ...,\n",
       "          2.50000000e+01,   9.76000000e+02,   3.13000000e+02],\n",
       "       [  1.44000000e+02,   3.73000000e+02,   1.47000000e+02, ...,\n",
       "          2.50000000e+01,   3.03000000e+02,   2.59200000e+03]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = ratings.dot(train.T) + 1e-9\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 9.41283858874\n",
      "Item-based CF MSE: 12.8813660348\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(train, item_similarity, kind='item')\n",
    "user_prediction = predict(train, user_similarity, kind='user')\n",
    "\n",
    "print('User-based CF MSE: ' + str(get_mse(user_prediction, test)))\n",
    "print('Item-based CF MSE: ' + str(get_mse(item_prediction, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    \n",
    "    for i in range(ratings.shape[0]):\n",
    "        # note! the [::-1] craziness is just a numpy trick to \n",
    "        # reverse the array. we're doing this because otherwise\n",
    "        # it is sorted in the direction opposite of what we want\n",
    "        # -- lowest to highest, so least to most similar. \n",
    "        # we flip this around then take the top k.\n",
    "        top_k_users =  np.argsort(similarity[:,i])[::-1][:k] #[np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "        \n",
    "        for j in range(ratings.shape[1]):\n",
    "            pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "            pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k User-based CF MSE: 7.94329177034\n"
     ]
    }
   ],
   "source": [
    "pred = predict_topk(train, user_similarity, k=40)\n",
    "print('Top-k User-based CF MSE: ' + str(get_mse(pred, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_array = [5, 15, 30, 50, 100, 200]\n",
    "user_train_mse = []\n",
    "user_test_mse = []\n",
    "item_test_mse = []\n",
    "item_train_mse = []\n",
    "\n",
    "def get_mse(pred, actual):\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "for k in k_array:\n",
    "    user_pred = predict_topk(train, user_similarity, k=k)\n",
    "    \n",
    "    user_train_mse += [get_mse(user_pred, train)]\n",
    "    user_test_mse += [get_mse(user_pred, test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pal = sns.color_palette(\"Set2\", 2)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(k_array, user_train_mse, c=pal[0], label='User-based train', alpha=0.5, linewidth=5)\n",
    "plt.plot(k_array, user_test_mse, c=pal[0], label='User-based test', linewidth=5)\n",
    "\n",
    "plt.legend(loc='best', fontsize=20)\n",
    "plt.xticks(fontsize=16);\n",
    "plt.yticks(fontsize=16);\n",
    "plt.xlabel('k', fontsize=30);\n",
    "plt.ylabel('MSE', fontsize=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
