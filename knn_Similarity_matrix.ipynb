{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  label\n",
       "0       1      661       3      0\n",
       "1       1      914       3      0\n",
       "2       1      594       4      0\n",
       "3       1      938       4      0\n",
       "4       1     2687       3      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide warnings to keep things tidy.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "matplotlib.style.use('ggplot') # make things a bit prettier.\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "import math\n",
    "from sklearn import metrics\n",
    "df = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/FirstRatingsMatrix.csv\", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "uniq_userid = df.UserID.unique()\n",
    "sorted_uniq_userid = sorted(uniq_userid)\n",
    "uindex = 0\n",
    "user_index = {}\n",
    "for n in sorted_uniq_userid:\n",
    "    user_index[n] = uindex\n",
    "    uindex += 1\n",
    "print user_index[77]\n",
    "uniq_movieid = df.MovieID.unique()\n",
    "sorted_uniq_movieid = sorted(uniq_movieid)\n",
    "mindex = 0\n",
    "movie_index = {}\n",
    "for n in sorted_uniq_movieid:\n",
    "    movie_index[n] = mindex\n",
    "    mindex += 1\n",
    "print movie_index[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n users: 6037\n",
      "n movies: 727\n"
     ]
    }
   ],
   "source": [
    "n_users = df.UserID.unique().shape[0]\n",
    "print(\"n users: %s\" % n_users)\n",
    "n_movies = df.MovieID.unique().shape[0]\n",
    "print(\"n movies: %s\" % n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_clust_ratings = np.zeros((n_users,n_movies))\n",
    "for row in df.itertuples():\n",
    "    # row[1] will the user_id; row[2] the \n",
    "    # rating (see also my note below).\n",
    "    # the -1 2s to move to 0 indexing.\n",
    "    first_clust_ratings[user_index[row[1]]-1, movie_index[row[2]]-1] = row[3]\n",
    "first_clust_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 5.18%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(first_clust_ratings.nonzero()[0]))\n",
    "sparsity /= (first_clust_ratings.shape[0] * first_clust_ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_split(ratings):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        if len(ratings[user, :].nonzero()[0]) > 5:\n",
    "            # sample 6 ratings from each user to use\n",
    "            # as 'test' data\n",
    "            test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                                size=6, \n",
    "                                                replace=False)\n",
    "            # effectively remove these from the training\n",
    "            # set\n",
    "            train[user, test_ratings] = 0.\n",
    "            test[user, test_ratings] = ratings[user, test_ratings]\n",
    "           \n",
    "    # make sure that test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(first_clust_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(ratings, kind='user', epsilon=1e-9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "        print(sim)\n",
    "    elif kind == 'item':\n",
    "        # we need only flip the dimensions around \n",
    "        # to do item based similarity!\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / (norms * norms.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.95000000e+02   4.10000000e+01   1.00000000e-09 ...,   3.60000000e+01\n",
      "    5.70000000e+01   1.00000000e-09]\n",
      " [  4.10000000e+01   9.80000000e+01   1.00000000e-09 ...,   1.00000000e-09\n",
      "    3.10000000e+01   1.00000000e-09]\n",
      " [  1.00000000e-09   1.00000000e-09   2.50000000e+01 ...,   1.00000000e-09\n",
      "    2.00000000e+01   1.00000000e-09]\n",
      " ..., \n",
      " [  3.60000000e+01   1.00000000e-09   1.00000000e-09 ...,   3.71000000e+02\n",
      "    8.60000000e+01   1.60000000e+01]\n",
      " [  5.70000000e+01   3.10000000e+01   2.00000000e+01 ...,   8.60000000e+01\n",
      "    6.76000000e+02   1.00000000e-09]\n",
      " [  1.00000000e-09   1.00000000e-09   1.00000000e-09 ...,   1.60000000e+01\n",
      "    1.00000000e-09   7.30000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = similarity(train, kind='user')\n",
    "item_similarity = similarity(train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.95000000e+02,   6.10000000e+01,   1.00000000e-09, ...,\n",
       "          3.60000000e+01,   5.70000000e+01,   1.00000000e-09],\n",
       "       [  7.70000000e+01,   9.80000000e+01,   1.00000000e-09, ...,\n",
       "          2.00000000e+01,   6.60000000e+01,   1.00000000e-09],\n",
       "       [  3.20000000e+01,   1.60000000e+01,   2.50000000e+01, ...,\n",
       "          1.50000000e+01,   5.30000000e+01,   1.00000000e-09],\n",
       "       ..., \n",
       "       [  3.60000000e+01,   1.00000000e-09,   1.00000000e-09, ...,\n",
       "          3.71000000e+02,   1.22000000e+02,   1.60000000e+01],\n",
       "       [  5.70000000e+01,   3.10000000e+01,   2.00000000e+01, ...,\n",
       "          8.60000000e+01,   6.76000000e+02,   1.00000000e-09],\n",
       "       [  1.00000000e-09,   1.00000000e-09,   2.00000000e+01, ...,\n",
       "          3.70000000e+01,   1.60000000e+01,   7.30000000e+01]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = first_clust_ratings.dot(train.T) + 1e-9\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 9.12508205207\n",
      "Movie-based CF MSE: 12.0897997254\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(train, item_similarity, kind='item')\n",
    "user_prediction = predict(train, user_similarity, kind='user')\n",
    "print('User-based CF MSE: ' + str(get_mse(user_prediction, test)))\n",
    "print('Movie-based CF MSE: ' + str(get_mse(item_prediction, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2321</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1566</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  label\n",
       "0       1     2918       4      1\n",
       "1       1     2321       3      1\n",
       "2       1     1270       5      1\n",
       "3       1     1566       4      1\n",
       "4       1      588       4      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_second = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/SecondRatingsMatrix.csv\", header=0)\n",
    "df_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniq_userid = df_second.UserID.unique()\n",
    "sorted_uniq_userid = sorted(uniq_userid)\n",
    "uindex = 0\n",
    "user_index = {}\n",
    "for n in sorted_uniq_userid:\n",
    "    user_index[n] = uindex\n",
    "    uindex += 1\n",
    "uniq_movieid = df_second.MovieID.unique()\n",
    "sorted_uniq_movieid = sorted(uniq_movieid)\n",
    "mindex = 0\n",
    "movie_index = {}\n",
    "for n in sorted_uniq_movieid:\n",
    "    movie_index[n] = mindex\n",
    "    mindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n users: 5963\n",
      "n movies: 558\n"
     ]
    }
   ],
   "source": [
    "n_users = df_second.UserID.unique().shape[0]\n",
    "print(\"n users: %s\" % n_users)\n",
    "n_movies = df_second.MovieID.unique().shape[0]\n",
    "print(\"n movies: %s\" % n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  3.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  5.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_clust_ratings = np.zeros((n_users,n_movies))\n",
    "for row in df_second.itertuples():\n",
    "    # row[1] will the user_id; row[2] the \n",
    "    # rating (see also my note below).\n",
    "    # the -1 2s to move to 0 indexing.\n",
    "    second_clust_ratings[user_index[row[1]]-1, movie_index[row[2]]-1] = row[3]\n",
    "second_clust_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 5.60%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(second_clust_ratings.nonzero()[0]))\n",
    "sparsity /= (second_clust_ratings.shape[0] * second_clust_ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(second_clust_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.90000000e+01   6.00000000e+00   5.00000000e+00 ...,   9.00000000e+00\n",
      "    3.50000000e+01   1.00000000e-09]\n",
      " [  6.00000000e+00   1.21000000e+02   1.00000000e-09 ...,   3.80000000e+01\n",
      "    4.10000000e+01   1.00000000e-09]\n",
      " [  5.00000000e+00   1.00000000e-09   3.07000000e+02 ...,   1.00000000e-09\n",
      "    6.50000000e+01   1.00000000e-09]\n",
      " ..., \n",
      " [  9.00000000e+00   3.80000000e+01   1.00000000e-09 ...,   3.25000000e+02\n",
      "    6.90000000e+01   1.60000000e+01]\n",
      " [  3.50000000e+01   4.10000000e+01   6.50000000e+01 ...,   6.90000000e+01\n",
      "    4.90000000e+02   1.00000000e-09]\n",
      " [  1.00000000e-09   1.00000000e-09   1.00000000e-09 ...,   1.60000000e+01\n",
      "    1.00000000e-09   1.60000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = similarity(train, kind='user')\n",
    "item_similarity = similarity(train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.90000000e+01,   6.00000000e+00,   1.40000000e+01, ...,\n",
       "          2.50000000e+01,   5.10000000e+01,   1.00000000e-09],\n",
       "       [  6.00000000e+00,   1.21000000e+02,   2.70000000e+01, ...,\n",
       "          3.80000000e+01,   7.30000000e+01,   1.00000000e-09],\n",
       "       [  8.00000000e+00,   1.00000000e-09,   3.07000000e+02, ...,\n",
       "          1.00000000e-09,   8.40000000e+01,   1.00000000e-09],\n",
       "       ..., \n",
       "       [  9.00000000e+00,   4.60000000e+01,   1.00000000e-09, ...,\n",
       "          3.25000000e+02,   1.00000000e+02,   1.60000000e+01],\n",
       "       [  3.50000000e+01,   5.10000000e+01,   6.50000000e+01, ...,\n",
       "          6.90000000e+01,   4.90000000e+02,   1.00000000e-09],\n",
       "       [  9.00000000e+00,   1.50000000e+01,   1.00000000e-09, ...,\n",
       "          3.60000000e+01,   3.00000000e+01,   1.60000000e+01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = second_clust_ratings.dot(train.T) + 1e-9\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 9.09635971233\n",
      "Movie-based CF MSE: 12.0976455214\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(train, item_similarity, kind='item')\n",
    "user_prediction = predict(train, user_similarity, kind='user')\n",
    "print('User-based CF MSE: ' + str(get_mse(user_prediction, test)))\n",
    "print('Movie-based CF MSE: ' + str(get_mse(item_prediction, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1545</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  label\n",
       "0       1     3408       4      2\n",
       "1       1     1287       5      2\n",
       "2       1      527       5      2\n",
       "3       1     1097       4      2\n",
       "4       1     1545       4      2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Third = pd.read_csv(\"/Users/sushma/Desktop/DM_Git/Recommender_System/ThirdRatingsMatrix.csv\", header=0)\n",
    "df_Third.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniq_userid = df_Third.UserID.unique()\n",
    "sorted_uniq_userid = sorted(uniq_userid)\n",
    "uindex = 0\n",
    "user_index = {}\n",
    "for n in sorted_uniq_userid:\n",
    "    user_index[n] = uindex\n",
    "    uindex += 1\n",
    "uniq_movieid = df_Third.MovieID.unique()\n",
    "sorted_uniq_movieid = sorted(uniq_movieid)\n",
    "mindex = 0\n",
    "movie_index = {}\n",
    "for n in sorted_uniq_movieid:\n",
    "    movie_index[n] = mindex\n",
    "    mindex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n users: 5981\n",
      "n movies: 685\n"
     ]
    }
   ],
   "source": [
    "n_users = df_Third.UserID.unique().shape[0]\n",
    "print(\"n users: %s\" % n_users)\n",
    "n_movies = df_Third.MovieID.unique().shape[0]\n",
    "print(\"n movies: %s\" % n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_clust_ratings = np.zeros((n_users,n_movies))\n",
    "for row in df_Third.itertuples():\n",
    "    # row[1] will the user_id; row[2] the \n",
    "    # rating (see also my note below).\n",
    "    # the -1 2s to move to 0 indexing.\n",
    "    third_clust_ratings[user_index[row[1]]-1, movie_index[row[2]]-1] = row[3]\n",
    "third_clust_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 4.06%\n"
     ]
    }
   ],
   "source": [
    "sparsity = float(len(third_clust_ratings.nonzero()[0]))\n",
    "sparsity /= (third_clust_ratings.shape[0] * third_clust_ratings.shape[1])\n",
    "sparsity *= 100\n",
    "print('sparsity: {:4.2f}%'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(third_clust_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.79000000e+02   2.00000000e+01   4.50000000e+01 ...,   2.00000000e+01\n",
      "    2.28000000e+02   3.60000000e+01]\n",
      " [  2.00000000e+01   6.40000000e+01   8.00000000e+00 ...,   1.00000000e-09\n",
      "    4.40000000e+01   1.00000000e-09]\n",
      " [  4.50000000e+01   8.00000000e+00   7.00000000e+01 ...,   1.60000000e+01\n",
      "    4.60000000e+01   1.00000000e-09]\n",
      " ..., \n",
      " [  2.00000000e+01   1.00000000e-09   1.60000000e+01 ...,   7.30000000e+01\n",
      "    2.00000000e+01   1.00000000e-09]\n",
      " [  2.28000000e+02   4.40000000e+01   4.60000000e+01 ...,   2.00000000e+01\n",
      "    1.29300000e+03   2.80000000e+01]\n",
      " [  3.60000000e+01   1.00000000e-09   1.00000000e-09 ...,   1.00000000e-09\n",
      "    2.80000000e+01   8.00000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = similarity(train, kind='user')\n",
    "item_similarity = similarity(train, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.79000000e+02,   4.00000000e+01,   5.50000000e+01, ...,\n",
       "          2.00000000e+01,   2.73000000e+02,   3.60000000e+01],\n",
       "       [  2.00000000e+01,   6.40000000e+01,   8.00000000e+00, ...,\n",
       "          1.00000000e-09,   4.40000000e+01,   1.00000000e-09],\n",
       "       [  4.50000000e+01,   8.00000000e+00,   7.00000000e+01, ...,\n",
       "          1.60000000e+01,   4.60000000e+01,   1.00000000e-09],\n",
       "       ..., \n",
       "       [  4.00000000e+01,   1.00000000e-09,   1.60000000e+01, ...,\n",
       "          7.30000000e+01,   7.60000000e+01,   1.00000000e-09],\n",
       "       [  2.52000000e+02,   4.40000000e+01,   4.60000000e+01, ...,\n",
       "          2.00000000e+01,   1.29300000e+03,   2.80000000e+01],\n",
       "       [  7.60000000e+01,   2.00000000e+01,   4.10000000e+01, ...,\n",
       "          1.60000000e+01,   1.10000000e+02,   8.00000000e+01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = third_clust_ratings.dot(train.T) + 1e-9\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 10.764265726\n",
      "Movie-based CF MSE: 14.0112636152\n"
     ]
    }
   ],
   "source": [
    "item_prediction = predict(train, item_similarity, kind='item')\n",
    "user_prediction = predict(train, user_similarity, kind='user')\n",
    "print('User-based CF MSE: ' + str(get_mse(user_prediction, test)))\n",
    "print('Movie-based CF MSE: ' + str(get_mse(item_prediction, test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
